# Conclusion and future plans {#ch:conclusion}

In this thesis, I present a systematic approach for visualizing and analyzing large temporal data distributions. The building blocks of this framework are presented in this thesis. Chapter \@ref(ch:gravitas) includes tools for computing all cyclic granularities as well as a recommendation system for selecting pairs of granularities that may be effectively investigated together. These temporal granularities may be used to generate data visualizations to search for patterns, associations, and anomalies. However, when there are many granularities that can be constructed for a time period, there will also be too many possible displays to decide which might be the more interesting to display. Chapter \@ref(ch:hakear) presents a framework for selecting displays that are interesting, with the greatest differences between the displayed distributions, and ranking them in order of priority for capturing the most variation. Both of these are used for studying patterns in individual time series or comparing a few time series together. In Chapter \@ref(ch:gracsr), it is extended to allow for the exploration of distributions for many time series at the same time by clustering them based on probability distributions across informative cyclic granularities. Through the use of probability distribution, this technique is more comprehensive in recognizing clusters with recurring patterns over many important granularities and more resilient to noisy, patchy, and uneven length time series.

```{r software-initial, echo = FALSE, cache = FALSE, include = FALSE}
read_chunk('scripts/software.R')
```

## Software development

```{r software-impact}
```

This thesis focuses on integrating research approaches into open source R packages such as **gravitas**, **hakear**, and **gracsr**.

<!-- Figure \@ref(fig:software-ghcommits) gives an overview of my Git commits to these repositories, and Figure \@ref(fig:software-downloads) shows the daily downloads of the packages from the RStudio mirror (one of 90 CRAN mirrors) since they were available on CRAN. -->

<!-- ```{r software-ghcommits, fig.cap = "(ref:software-ghcommits-cap)"} -->
<!-- include_graphics("img/pkg-commits.png") -->
<!-- ``` -->

<!-- (ref:software-ghcommits-cap) Patterns of my package development effort during my PhD years based on Git commits to three repositories, sugrrants, tsibble, and mists. Scatter plots of weekly totals are overlaid with a loess smoother. The **sugrrants** package was the first project with much initial energy, followed by small constant maintenance. The **tsibble** package has been a major project with ongoing constant development and bursts of effort in response to users' feedback. The **mists** package has been a recent intense project. -->

<!-- # ```{r software-downloads, fig.height = 3, fig.cap = "(ref:software-downloads-cap)"} -->
<!-- # ``` -->
<!-- #  -->
<!-- # (ref:software-downloads-cap) Impact of these works (sugrrants and tsibble) as measured by daily downloads (on square root scale) from the RStudio mirror since they landed on CRAN. The **tsibble** package has an increasing trend, suggesting the steady adoption of the new data structure. -->

### gravitas

The **gravitas** package provides very general tools to compute and manipulate cyclic granularities, and to generate plots displaying distributions conditional on those granularities. It can be utilized in non-temporal cases for which a hierarchical structure can be construed similar to time. It is on CRAN. The website (<https://sayani07.github.io/gravitas>) includes full documentation and two vignettes about the package usage.  There has been a grand total of 12K downloads from the RStudio mirror dating from 2020-11-01 to 2021-11-01.

### hakear 

The open-source R package `hakear` is available on Github (https://github.com/Sayani07/hakear) to implement ideas presented in Chapter \@ref(ch:hakear). Given a `tsibble` and context granularities of interest, the function `wpd()` provides support for computing the wpd for each cyclic granularities or pair of granularities and `select_harmonies()` chooses the ones with significant patterns and ranks them from highest to lowest wpd.

### gracsr

The open-source R package `gracsr` is available on Github (https://github.com/Sayani07/gracsr) to implement ideas presented in Chapter \@ref(ch:gracsr). The package provides functions to carry out the entire clustering methodology discussed in the paper. It is still a work in progress and has won the ACEMS Business Analytics Prize 2021 with a prize money of AUD 3000, which would be utilized in polishing this package and preparing it for CRAN.

## Future work

### Putting all functionalities on CRAN

I plan to integrate `hakear` with `gravitas` as one R package to systematically exploring few time series, whereas `gracsr` would provide the clustering framework for exploring many time series together. I plan to run it through https://ropensci.org/software-review/ to develop them further for more visibility and efficient usage.


### Scaling up the clustering method to incorporate large uncertainty and improved computational efficiency that comes with large data

With the volume of data projected to grow in the future, potentially leading to increased variability in patterns, research is needed to understand the issues that may arise with the existing methodology and how to adapt our current algorithm. Computational efficiency is also critical when scaling up for analysis of huge data sets, let alone when adding features to existing highly dimensional data structures.

### Comparing our clustering method with other benchmark methods

Testing needs to be carried out with non-hierarchy based clustering methods to see whether these distances perform better with other algorithms. Also, to evaluate how much information is lost when aggregating individual level demand versus distributions.

### Check generalizability of our methods

We provide solutions that are realistically applicable to any temporal data observed more than once per year. We could just verify its value inÂ the electricity smart meter context. With numerous open-source benchmark data sets accessible, it is necessary to test how well the approaches operate in various disciplines.


## Final words

