# Introduction {#ch:intro}

<!-- Introduction -->
<!-- Motivation & Background -->
<!-- Outline of the thesis -->

<!-- To tame the complexity of time, breaking it into years, months, weeks, days and so on in a hierarchical manner is a common way to relate data to time. Such dicrete human made abstractions of time can be thought of as time granularities.(Aigner et al., 2008). -->


<!-- introducing the overall field-->
With the availability of data at more and more finer time scales, exploration of time series data may be required to be carried out across both finer and coarser scales to draw useful inferences about the underlying process. For example, data collected at an hourly scale could be analyzed using coarser temporal scales such as days, months or quarters. This approach requires deconstructing time in various possible ways. Moreover, often it might be interesting to capture calendar or periodic effects like month-of-year, day-of-week or hour-of-day. They help us in answering questions like if certain levels of those time deconstructions are characterized by unusual/routine values of the observed variable. For example, certain days of the week or months of the year are likely to be characterized by higher values. It is important to be able to navigate through all the temporal deconstructions that accommodate for periodicities to have multiple perspectives of the observed data. This idea aligns with the notion of EDA (Tukey 1977) which emphasizes the use of multiple perspectives on data to help formulate hypotheses before proceeding to hypothesis testing.


<!-- outline the intro chapter structure -->

This chapter will provide an introduction to the study by first discussing the background and context, followed by the research aims, objectives and questions.

<!-- Background -->

The motivation for this work comes from the desire to provide methods to better understand large quantities of measurements on energy usage reported by smart meters in household across Australia, and indeed many parts of the world. Smart meters currently provide half-hourly use in kwh for each household, from the time that they were installed, some as early as 2012. Households are distributed geographically, and have different demographic properties such as the existence of solar panels, central heating or air conditioning. The behavioral patterns in households vary substantially, for example, some families use a dryer for their clothes while others hang them on a line, and some households might consist of night owls, while others are morning larks. It is common to see aggregates of usage across households, total kwh used each half hour by state, for example, because energy companies need to understand maximum loads that they will have to plan ahead to accommodate. But studying overall energy use hides the distributions of usage at finer scales, and making it more difficult to find solutions to improve energy efficiency.

<!-- introduce the specific problem  -->


<!-- ## change in data structure as a result of transitioning from linear to cyclic deconstructions -->
<!-- + Existing approaches, why we need to drill down, or why we want to -- probability distributions -->
However, restructuring time in this manner leads to restructured data where each level of the time deconstructions correspond to multiple values of the observed variable. It is common to see aggregation or summarization of these multiple observations with a unique value to study calendar effects. For example, using aggregates of usage across each hour/half-hour has been common in the literature because energy companies need to plan for maximum loads on the network. But studying overall energy use hides the distributions of usage at finer scales, and making it more difficult to find solutions to improve energy efficiency. Summarizing the probability distribution of these multiple observations to capture both the shape and uncertainty could be a potential way to understand the underlying distribution of these observations. Studying probability distributions is likely to focus on features of the data which are not transparent through raw data or a unique summary statistic.

<!-- Following research objectives would facilitate the achievement of this aim -->
<!-- Research objectives -->

<!-- ## Research aims -->

Hence, the overarching research goal is to study the periodic behavior of temporal data in a structured way by studying the probability distributions by best exploiting the characteristics of time. Slicing and dicing the data in all possible temporal scales as suggested by EDA can be a daunting task as it leads to a myriad of possibilities. This inspires the research presented in this thesis, which aims to provide a platform to systematically explore periodicities in temporal data and support finding regular patterns or anomalies, explore clusters of behaviors or summarize the behavior. The first part of the work discusses computation of all possible combinations of cyclic time granularities and a graphical mapping such that distributions of a numeric response variable is displayed across combinations of two cyclic granularities. Even analyzing the distribution of the measured variable across two cyclic granularities at once could amount to displaying many plots in search of potential  patterns. Thus, the first part of the research also introduces "harmony" to denote pairs of granularities that could be analyzed together and reduces the search from all possible options. But this approach is still overwhelming for human consumption because there would still be huge number of harmonies. Hence, the second part of the research extends this work and narrows the search further by finding pair of cyclic granularities which are informative enough and rank them according to their importance. However, to explore periodic patterns of many households, we have to resort to clustering which has been addressed in the third part of the research. Although the motivation came through the smart meter example, this is a problem that is relevant to any temporal data observed more than once per year.

## Visualizing probability distributions across bivariate cyclic temporal granularities {#sec:gravitas}

Deconstructing a time index into time granularities can assist in exploration and automated analysis of large temporal data sets. This paper describes classes of time deconstructions using linear and cyclic time granularities. Linear granularities respect the linear progression of time such as hours, days, weeks and months. Cyclic granularities can be circular such as hour-of-the-day, quasi-circular such as day-of-the-month, and aperiodic such as public holidays. The hierarchical structure of granularities creates a nested ordering: hour-of-the-day and second-of-the-minute are single-order-up. Hour-of-the-week is multiple-order-up, because it passes over day-of-the-week. Methods are provided for creating all possible granularities for a time index. A recommendation algorithm provides an indication whether a pair of granularities can be meaningfully examined together (a "harmony"), or when they cannot (a "clash").  
 
 Time granularities can be used to create data visualizations to explore for periodicities, associations and anomalies. The granularities form categorical variables (ordered or unordered) which induce groupings of the observations. Assuming a numeric response variable, the resulting graphics are then displays of distributions compared across combinations of categorical variables.  
  
 The methods implemented in the open source R package `gravitas` are consistent with a tidy workflow, with probability distributions examined using the range of graphics available in `ggplot2`.

 <!-- This chapter contains a literature review related to linear granularities. -->
 
## Detecting distributional differences between temporal granularities for exploratory time series analysis {#sec:hakear}

This work is a natural extension of Chapter \@ref(ch:gravitas). Many, many other displays might be built using different granularities, such as day-of-week, day-of-month, weekday/weekend, and so on. However, only a handful of them may be interesting, revealing major patterns. Determining which displays exhibit "significant" distributional differences between cyclic granularity categories and plotting only these would allow for more efficient exploration. Furthermore, a few of the displays in this collection will be more engaging than others. This chapter provides a new distance metric for selecting and ranking the multiple granularities. The statistical significance of potential visual discoveries is aided by selecting a threshold for the proposed numerical distance measure. The distance measure is computed for a single or pairs of cyclic granularities, and it can be compared across different cyclic granularities as well as a collection of time series. This chapter also includes a case study using residential smart meter data from Melbourne to demonstrate how the suggested methodology may be utilised to automatically find temporal granularities with significant distributional differences. The methods are implemented in the open-source R package 'hakear.'

## Clustering time series based on probability distributions across temporal granularities {#sec:gracsr}

In this chapter, we look at the problem of using clustering to discover patterns in a large number of univariate time series across multiple temporal granularities. Time series clustering research is gaining traction as more data is collected at finer temporal resolution, over longer time periods, and for a larger number of individuals/entities. Many disciplines have noisy, patchy, uneven, and asynchronous time series that make it difficult to search for similarities. We propose a method for overcoming these constraints by calculating distances between time series based on probability distributions at various temporal granularities. Because they are based on probability distributions, these distances are resistant to missing or noisy data and aid in dimension reduction. When fed into a clustering algorithm, the distances can be used to divide large data sets into small pockets of similar repetitive behaviour. These subgroups can then be analysed separately or used as distinct prototype behaviours in classification problems. The proposed method was tested on a group of residential electricity consumers from the Australian smart meter data set to show that it can generate meaningful clusters. This chapter includes a brief review of the literature on traditional time series clustering and, more specifically, clustering residential smart meter data.



<!-- Time series clustering research is gaining a lot of importance with more and more time series data recorded at much finer temporal resolution, for a longer period of time and for a larger number of individuals/entities.Similarity searches amongst these long time series are often limited by the type of noisy, patchy, unequal and asynchronous time series common in many fields. In this paper we propose a strategy to alleviate these limitations by  clustering time series based on probability distributions across cyclic temporal granularities. Cyclic granularities are temporal deconstructions of a time period into units such as hour-of-the-day, work-day/weekend, which can be useful for measuring repetitive patterns in large univariate time series data. Thus, looking at the probability distributions across cyclic granularity leads to a method which is robust to missing or noisy data, helps in dimension reduction while ensuring small pockets of similar repetitive behaviors. The method is applied to electricity smart meter dat -->
<!-- The suggested approach was evaluated on a set of benchmark time series on residential electricity customers. The empirical results show that our approach is able to yield meaningful clusters. -->

## Summary

The thesis is structured as follows. Chapter \@ref(ch:gravitas) provides details of the cyclic granularities, different classes, and computation, and also its usage in exploratory time series analysis through applications. This is implemented in the R package **gravitas**. Chapter \@ref(ch:hakear) provides guidance on how to choose significant cyclic granularities, which are likely to have interesting patterns across its categories. This is available as the R package **hakear**. The chapter @ref (ch: gracsr) provides similarity measures for comparing multiple time series.This is in the developing R package **gracsr**. Chapter \@ref(ch:conclusion) summarizes the software tools developed for the work, and discusses some future plans.
