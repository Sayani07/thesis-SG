<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.1 Introduction | Visualization and analysis of probability distributions of large temporal data</title>
  <meta name="description" content="4.1 Introduction | Visualization and analysis of probability distributions of large temporal data" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.1 Introduction | Visualization and analysis of probability distributions of large temporal data" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.1 Introduction | Visualization and analysis of probability distributions of large temporal data" />
  
  
  

<meta name="author" content="Sayani Gupta" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4-ch-gracsr.html"/>
<link rel="next" href="4.2-sec:methodology.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="template/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./"> </a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="ch-abstract.html"><a href="ch-abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="ch-thanks.html"><a href="ch-thanks.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="ch-preface.html"><a href="ch-preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-ch-intro.html"><a href="1-ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-sec:gravitas.html"><a href="1.1-sec:gravitas.html"><i class="fa fa-check"></i><b>1.1</b> Visualizing probability distributions across bivariate cyclic temporal granularities</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-sec:hakear.html"><a href="1.2-sec:hakear.html"><i class="fa fa-check"></i><b>1.2</b> Detecting distributional differences between temporal granularities for exploratory time series analysis</a></li>
<li class="chapter" data-level="1.3" data-path="1.3-sec:gracsr.html"><a href="1.3-sec:gracsr.html"><i class="fa fa-check"></i><b>1.3</b> Clustering time series based on probability distributions across temporal granularities</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-thesis-structure.html"><a href="1.4-thesis-structure.html"><i class="fa fa-check"></i><b>1.4</b> Thesis structure</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-ch-gravitas.html"><a href="2-ch-gravitas.html"><i class="fa fa-check"></i><b>2</b> Visualizing probability distributions across bivariate cyclic temporal granularities</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-introduction.html"><a href="2.1-introduction.html"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-sec:linear-time.html"><a href="2.2-sec:linear-time.html"><i class="fa fa-check"></i><b>2.2</b> Linear time granularities</a></li>
<li class="chapter" data-level="2.3" data-path="2.3-sec:cyclic-gran.html"><a href="2.3-sec:cyclic-gran.html"><i class="fa fa-check"></i><b>2.3</b> Cyclic time granularities</a></li>
<li class="chapter" data-level="2.4" data-path="2.4-sec:data-structure.html"><a href="2.4-sec:data-structure.html"><i class="fa fa-check"></i><b>2.4</b> Data structure</a></li>
<li class="chapter" data-level="2.5" data-path="2.5-sec:visualization.html"><a href="2.5-sec:visualization.html"><i class="fa fa-check"></i><b>2.5</b> Visualization</a></li>
<li class="chapter" data-level="2.6" data-path="2.6-sec:application.html"><a href="2.6-sec:application.html"><i class="fa fa-check"></i><b>2.6</b> Applications</a></li>
<li class="chapter" data-level="2.7" data-path="2.7-sec:discussion.html"><a href="2.7-sec:discussion.html"><i class="fa fa-check"></i><b>2.7</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="thanksgravitas.html"><a href="thanksgravitas.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="supplement-gravitas.html"><a href="supplement-gravitas.html"><i class="fa fa-check"></i>Supplementary Materials</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch-hakear.html"><a href="3-ch-hakear.html"><i class="fa fa-check"></i><b>3</b> Detecting distributional differences between temporal granularities for exploratory time series analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-introduction-1.html"><a href="3.1-introduction-1.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-sec:computation-wpd.html"><a href="3.2-sec:computation-wpd.html"><i class="fa fa-check"></i><b>3.2</b> Proposed distance measure</a></li>
<li class="chapter" data-level="3.3" data-path="3.3-sec:rank-wpd.html"><a href="3.3-sec:rank-wpd.html"><i class="fa fa-check"></i><b>3.3</b> Ranking and selection of cyclic granularities</a></li>
<li class="chapter" data-level="3.4" data-path="3.4-sec:application-wpd.html"><a href="3.4-sec:application-wpd.html"><i class="fa fa-check"></i><b>3.4</b> Application to residential smart meter dataset</a></li>
<li class="chapter" data-level="3.5" data-path="3.5-discussion.html"><a href="3.5-discussion.html"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="3.6" data-path="3.6-supplementary-materials.html"><a href="3.6-supplementary-materials.html"><i class="fa fa-check"></i><b>3.6</b> Supplementary Materials</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch-gracsr.html"><a href="4-ch-gracsr.html"><i class="fa fa-check"></i><b>4</b> Clustering time series based on probability distributions across temporal granularities</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-introduction-2.html"><a href="4.1-introduction-2.html"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4.2-sec:methodology.html"><a href="4.2-sec:methodology.html"><i class="fa fa-check"></i><b>4.2</b> Clustering methodology</a></li>
<li class="chapter" data-level="4.3" data-path="4.3-sec:validation.html"><a href="4.3-sec:validation.html"><i class="fa fa-check"></i><b>4.3</b> Validation</a></li>
<li class="chapter" data-level="4.4" data-path="4.4-sec:application-gracsr.html"><a href="4.4-sec:application-gracsr.html"><i class="fa fa-check"></i><b>4.4</b> Application</a></li>
<li class="chapter" data-level="4.5" data-path="4.5-sec:discussion-gracsr.html"><a href="4.5-sec:discussion-gracsr.html"><i class="fa fa-check"></i><b>4.5</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="acknowledgments-1.html"><a href="acknowledgments-1.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="4.6" data-path="4.6-supplementary-materials-1.html"><a href="4.6-supplementary-materials-1.html"><i class="fa fa-check"></i><b>4.6</b> Supplementary Materials</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch-conclusion.html"><a href="5-ch-conclusion.html"><i class="fa fa-check"></i><b>5</b> Conclusion</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-original-contributions.html"><a href="5.1-original-contributions.html"><i class="fa fa-check"></i><b>5.1</b> Original contributions</a></li>
<li class="chapter" data-level="5.2" data-path="5.2-software-development.html"><a href="5.2-software-development.html"><i class="fa fa-check"></i><b>5.2</b> Software development</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-future-ideas.html"><a href="5.3-future-ideas.html"><i class="fa fa-check"></i><b>5.3</b> Future ideas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><strong><a href="https://github.com/rstudio/bookdown" target="blank">Proudly published with bookdown</a></strong></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Visualization and analysis of probability distributions of large temporal data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-2" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<!-- time series clustering and its challenges -->
<p>Time-series clustering is the process of unsupervised partitioning of <span class="math inline">\(n\)</span> time-series data into <span class="math inline">\(k\)</span> (<span class="math inline">\(k&lt;n\)</span>) meaningful groups such that homogeneous time-series are grouped together based on a certain similarity measure. The time-series features, length of time-series, representation technique, and, of course, the purpose of clustering time-series all influence the suitable similarity measure or distance metric to a meaningful level. The three primary methods to time series clustering (<span class="citation"><a href="bibliography.html#ref-liao2005clustering" role="doc-biblioref">Liao</a> (<a href="bibliography.html#ref-liao2005clustering" role="doc-biblioref">2005</a>)</span>) are algorithms that operate directly with distances or raw data points in the time or frequency domain (distance-based), with features derived from raw data (feature-based), or indirectly with models constructed from raw data (model-based). The efficacy of distance-based techniques is highly dependent on the distance measure utilized. Defining an appropriate distance measure for the raw time series may be a difficult task since it must take into account noise, variable lengths of time series, asynchronous time series, different scales, and missing data. Commonly used distance-based similarity measures as suggested by a decade review of time series clustering approaches (<span class="citation"><a href="bibliography.html#ref-Aghabozorgi2015-ct" role="doc-biblioref">Aghabozorgi, Seyed Shirkhorshidi, and Ying Wah</a> (<a href="bibliography.html#ref-Aghabozorgi2015-ct" role="doc-biblioref">2015</a>)</span>) are Euclidean, Pearson’s correlation coefficient and related distances, Dynamic Time Warping (DTW), Autocorrelation, Short time series distance, Piecewise regularization, cross-correlation between time series, or a symmetric version of the Kullback–Liebler distances (<span class="citation"><a href="bibliography.html#ref-liao2007clustering" role="doc-biblioref">Liao</a> (<a href="bibliography.html#ref-liao2007clustering" role="doc-biblioref">2007</a>)</span>) but on a vector time series data. Among these alternatives, Euclidean distances have high performance but need the same length of data over the same period, resulting in information loss regardless of whether it is on raw data or a smaller collection of features. DTW works well with time series of different lengths (<span class="citation"><a href="bibliography.html#ref-corradini2001dynamic" role="doc-biblioref">Corradini</a> (<a href="bibliography.html#ref-corradini2001dynamic" role="doc-biblioref">2001</a>)</span>), but it is incapable of handling missing observations. Surprisingly, probability distributions, which may reflect the inherent temporal structure of a time series have not been considered in determining time series similarity.</p>
<p>This work is motivated by a need to cluster a large collection of residential smart meter data, so that households can be grouped into similar energy usage patterns. These can be considered to be univariate time series of continuous values which are available at fine temporal scales. These time series data are long (with more and more data collected at finer resolutions), are asynchronous, with varying time lengths for different houses and sporadic missing values. Using probability distributions is a natural way to analyze this types of data because they are robust to uneven length, missing data, or noise. This paper proposes two approaches for obtaining pairwise similarities based on Jensen-Shannon distances between probability distributions across a selection of cyclic granularities. Cyclic temporal granularities <span class="citation">(<a href="bibliography.html#ref-Gupta2021-hakear" role="doc-biblioref">Gupta, Hyndman, and Cook 2021</a>)</span>, which are temporal deconstructions of a time period into units such as hour-of-the-day, work-day/weekend, can measure repetitive patterns in large univariate time series data. The resulting clusters are expected to group customers that have similar repetitive behaviors across cyclic granularities. The benefits of this approach are as follows.</p>
<ul>
<li>When using probability distributions, data does not have to be the same length or observed during the exact same time period (unless there is a structural pattern).</li>
</ul>
<!-- (for example, some customers observed only for holidays, others observed over non holidays or year of observation is different which can lead to technological advancement.) -->
<ul>
<li><p>Jensen-Shannon distances evaluate the distance between two distributions rather than raw data, which is less sensitive to missing observations and outliers than other conventional distance methods.</p></li>
<li><p>While most clustering algorithms produce clusters similar across just one temporal granularity, this technique takes a broader approach to the problem, attempting to group observations with similar distributions across all interesting cyclic granularities.</p></li>
<li><p>It is reasonable to define a time series based on its degree of trend and seasonality, and to take these characteristics into account while clustering it. The modification of the data structure by taking into account probability distributions across cyclic granularities assures that there is no trend and that seasonal variations are handled independently. As a result, there is no need to de-trend or de-seasonalize the data before applying the clustering method. For similar reasons, there is no need to exclude holiday or weekend routines.</p></li>
</ul>
<!--_Background and motivation_-->
<p>The primary application of this work is data from the Smart Grid, Smart City (SGSC) project (2010–2014) available through the <a href="https://data.gov.au/data/organization/doee">Department of the Environment and Energy</a>. Half-hourly measurements of usage for more than 13,000 household electricity smart meters is provided from from October 2011 to March 2014. <!--Larger data sets include greater uncertainty about customer behavior due to growing variety of customers.--> Households vary in size, location, and amenities such as solar panels, central heating, and air conditioning. The behavioral patterns differ amongst customers due to many temporal dependencies. Some households use a dryer, while others dry their clothes on a line. Their weekly usage profile may reflect this. They may vary monthly, with some customers using more air conditioners or heaters than others, while having equivalent electrical equipment and weather circumstances. Some customers are night owls, while others are morning larks. Daily energy usage varies depending on whether customers stay home or work away from home. Age, lifestyle, family composition, building attributes, weather, availability of diverse electrical equipment, among other factors, make the task of properly segmenting customers into comparable energy behavior complex. The challenge is to be able to cluster consumers into these type of expected patterns, and other unexpected patterns, using only their energy usage history (<span class="citation"><a href="bibliography.html#ref-Ushakova2020-rl" role="doc-biblioref">Ushakova and Jankin Mikhaylov</a> (<a href="bibliography.html#ref-Ushakova2020-rl" role="doc-biblioref">2020</a>)</span>). <!--To safeguard the customers' privacy, it is probable that such information is not accessible. Also, energy suppliers may not always update client information, such as property features, in a timely manner.--> There is a growing need to have methods that can examine the energy usage heterogeneity observed in smart meter data and what are some of the most common power consumption patterns.</p>
<!-- _Related work_-->
<p>There is a growing body of literature focused on time series clustering related to smart meter data. <span class="citation"><a href="bibliography.html#ref-Tureczek2017-pb" role="doc-biblioref">Tureczek and Nielsen</a> (<a href="bibliography.html#ref-Tureczek2017-pb" role="doc-biblioref">2017</a>)</span> conducted a systematic study of over <span class="math inline">\(2100\)</span> peer-reviewed papers on smart meter data analytics. <!--None of the $34$ articles chosen for their emphasis use Australian smart meter data.--> The most often used algorithm is <span class="math inline">\(k\)</span>-means <span class="citation">(<a href="bibliography.html#ref-Rhodes2014-it" role="doc-biblioref">Rhodes et al. 2014</a>)</span>.
<span class="math inline">\(k\)</span>-means can be made to perform better by explicitly incorporating time series features such as correlation or cyclic patterns rather than performing it on raw data. To reduce dimensionality, several studies use principal component analysis (PCA) or factor analysis to pre-process smart-meter data before clustering (<span class="citation"><a href="bibliography.html#ref-Ndiaye2011-pf" role="doc-biblioref">Ndiaye and Gabriel</a> (<a href="bibliography.html#ref-Ndiaye2011-pf" role="doc-biblioref">2011</a>)</span>). PCA eliminates correlation patterns and decreases feature space, but loses interpretability. Other algorithms utilized in the literature include <span class="math inline">\(k\)</span>-means variants, hierarchical clustering, and greedy <span class="math inline">\(k\)</span>-medoids. Time series data, such as smart meter data, are not well-suited to any of the techniques mentioned in <span class="citation"><a href="bibliography.html#ref-Tureczek2017-pb" role="doc-biblioref">Tureczek and Nielsen</a> (<a href="bibliography.html#ref-Tureczek2017-pb" role="doc-biblioref">2017</a>)</span>. Only one study <span class="citation">(<a href="bibliography.html#ref-ozawa2016determining" role="doc-biblioref">Ozawa, Furusato, and Yoshida 2016</a>)</span> identified time series characteristics by first conducting a Fourier transformation, to convert data from time to frequency domain, followed by <span class="math inline">\(k\)</span>-means to cluster by greatest frequency. <span class="citation"><a href="bibliography.html#ref-Motlagh2019-yj" role="doc-biblioref">Motlagh, Berry, and O’Neil</a> (<a href="bibliography.html#ref-Motlagh2019-yj" role="doc-biblioref">2019</a>)</span> suggests that the time feature extraction is limited by the type of noisy, patchy, and unequal time-series common in residential customers and addresses model-based clustering by transforming the series into other objects such as structure or set of parameters which can be more easily characterized and clustered. <span class="citation">(<a href="bibliography.html#ref-chicco2010renyi" role="doc-biblioref">Chicco and Akilimali 2010</a>)</span> addresses information theory-based clustering such as Shannon or Renyi entropy and its variations. <span class="citation"><a href="bibliography.html#ref-Melnykov2013-sp" role="doc-biblioref">Melnykov</a> (<a href="bibliography.html#ref-Melnykov2013-sp" role="doc-biblioref">2013</a>)</span> discusses how outliers, noisy observations and scattered observations can complicate estimating mixture model parameters and hence the partitions. None of these methods focuses on exploring heterogeneity in repetitive patterns based on the dynamics of multiple temporal dependencies using probability distributions, which forms the basis of the methodology reported here.</p>
<!-- Given none of the methods use probability distributions across cyclic granularity to explore heterogeneity in different repetitive behaviors, we present a way to do that by presenting similarity through probability distributions across cyclic granularities.  -->
<p>This paper is organized as follows. Section~ provides the clustering methodology. Section~ shows data designs to validate our methods. Section~ discusses the application of the method to a subset of the real data. Finally, we summarize our results and discuss possible future directions in Section~.</p>
<!-- A typical clustering technique includes the following steps: (a) establishing distance (dissimilarity) and similarity through feature or model extraction and selection; and (b) selecting the clustering algorithm design. Distance measures could be time-domain based or frequency-domain (fast Fourier transform). -->
<!-- A model-based clustering works by transforming the series into other other objects such as structure or set of parameters which can be more easily characterized and clustered (@Motlagh2019-yj). [@chicco2010renyi] addresses information theory-based clustering such as Shannon or Renyi entropy and its variations. The essential temporal characteristics of the curves are defined or extracted using feature-based clustering. -->
<!-- This work -->
<!-- This is similar to a stochastic approach (@Motlagh2019-yj) to clustering, which proposes interpreting electricity demand as a random process and extracting time-series characteristics, or a model of the series, to enable unsupervised clustering. Unsupervised clustering is only as good as the features that are extracted/selected or the distance metrics that were utilized. Well-designed additional features may collect characteristics that default features cannot. Based on the underlying structure of the temporal data, this article offers new distance metric and features for clustering and applies them to actual smart-meter data. Firstly, the distance metric is based on probability distribution, which in our knowledge is the first attempt to cluster smart meter data using probability distributions. These recorded time series are asynchronous, with varying time lengths for different houses and missing observations. Taking probability distributions helps to deal with such data, while helping with dimension reduction in one hand but not losing too much information due to aggregation. Secondly, we recognise that most clustering algorithms only provide hourly energy profiles during the day, but this approach provides a wider approach to the issue, seeking to group consumers with similar shapes over all important cyclic granularities. Since cyclic granularities are considered instead of linear granularities, clustering would group customers that have similar repetitive behavior across more than one cyclic granularities across which patterns are expected to be significant.  -->
<!-- common similarity measures -->
<!-- electricity data structure -->
<!-- common similarity measures used there -->
<!-- lit review -->
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4-ch-gracsr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4.2-sec:methodology.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/earowang/thesis/edit/master/Rmd//04-gracsr.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
